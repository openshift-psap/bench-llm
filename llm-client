#!/bin/python3
import sys
import argparse
import subprocess
from typing import Dict, Optional
from dataclasses import dataclass

from jinja2 import Environment, FileSystemLoader

@dataclass
class CmdResult:
    rc: int
    stdout: Optional[str]
    stderr: Optional[str]

def run(cmd: str, capture_stdout: bool=False, capture_stderr: bool=False) -> CmdResult:
    ran = subprocess.run(cmd, shell=True, stdout=(subprocess.PIPE if capture_stdout else None), stderr=(subprocess.PIPE if capture_stderr else None))
    result = CmdResult(
        ran.returncode,
        None if not capture_stdout else ran.stdout.decode("utf-8"),
        None if not capture_stderr else ran.stderr.decode("utf-8"),
    )
    return result

def main():
    options = dict(
        repo_tag = 'main',
        config_output_format = 'json',
        config_output_dir = './output/',
        config_output_file = 'output-{concurrency:03d}.json',
        config_storage_type = 'local',
        config_dataset_file = 'datasets/openorca_large_subset_011.jsonl',
        config_dataset_max_queries = 1000,
        config_dataset_min_input_tokens = 0,
        config_dataset_max_input_tokens = 1024,
        config_dataset_min_output_tokens = 0,
        config_dataset_max_output_tokens = 1024,
        config_dataset_max_sequence_tokens = 2048,
        config_load_options_type = 'constant',
        config_load_options_concurrency = 1,
        config_load_options_duration = 20,
        config_plugin = 'openai_plugin',
        config_plugin_options_use_tls = False,
        config_plugin_options_streaming = True,
        config_plugin_options_model_name = 'flan-t5-small',
        config_plugin_options_host = 'http://route.to.host',
        config_plugin_options_endpoint = '/v1/completions',
        config_extra_metadata_replicas = 1
    )

    parser = argparse.ArgumentParser()

    for option_name, option_default in options.items():
        parser.add_argument(f"--{option_name}", default=option_default)

    args = parser.parse_args()

    # Download the correct branch of llm-load-test
    run("git clone https://github.com/openshift-psap/llm-load-test")
    run(f"cd llm-load-test && git checkout {args.repo_tag}")

    # Template the config file
    # Jinja2 template file should be copied from controller by Rickshaw
    environment = Environment(loader=FileSystemLoader("/tmp/templates/"))
    template = environment.get_template("config.yaml.j2")
    # Grab all the settings prefixed with 'config_' they correspond to fields in the
    # llm-load-test config file
    config_options_from_cli_args = {k: v for k, v in vars(args).items() if "config_" in k}
    complete_config = template.render(config_options_from_cli_args)
    with open("config.yaml", "w", encoding="utf-8") as f:
        f.write(complete_config)


    # Run llm-load-test
    run("cd llm-load-test && python3 load_test.py -c ../config.yaml")

    # Copy the output json file from llm-load-test to a known location; this
    # might be difficult since 'config_output_file' can include a variable that
    # is formatted
    run(f"cp llm-load-test/{args.config_output_dir}/{args.config_output_file} output.json")
    # Save all settings
    with open("settings.json", "w") as f:
        f.write(json.dumps(vars(args), ident=4))

    sys.exit(0)

if __name__ == "__main__":
    main()
