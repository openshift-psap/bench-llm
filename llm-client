#!/bin/python3

import sys

# Do this immediately to log as much of the execution as possible
fp_out = open("client_stdout.txt", "w")
fp_err = open("client_stderr.txt", "w")
sys.stdout = fp_out
sys.stderr = fp_err

import argparse
import subprocess
from typing import List, Literal, Optional, TypeAlias, Union, get_origin, get_args
from dataclasses import asdict, dataclass, field, fields, MISSING
from enum import Enum
import json

DEPENDENCIES = ["guidellm"]

def is_optional(field_t):
    return get_origin(field_t) is Union and type(None) in get_args(field_t)

@dataclass
class CmdResult:
    rc: int
    stdout: Optional[str]
    stderr: Optional[str]

class DataType(Enum):
    EMULATED = "emulated"
    FILE = "file"
    TRANSFORMERS = "transformers"

    def __str__(self):
        return self.value


class BackendEngine(Enum):
    OPENAI_SERVER = "openai_server"

    def __str__(self):
        return self.value

class RateType(Enum):
    SWEEP = "sweep"
    SYNCHRONOUS = "synchronous"
    THROUGHPUT = "throughput"
    CONSTANT = "constant"
    POISSON = "poisson"

    def __str__(self):
        return self.value

MaxRequests: TypeAlias = Union[int, Literal["dataset"]]

@dataclass
class Params:
    guidellm_target: str
    guidellm_data: str
    guidellm_data_type: DataType
    guidellm_backend: BackendEngine = BackendEngine.OPENAI_SERVER
    guidellm_model: Optional[str] = None
    guidellm_tokenizer: Optional[str] = None
    guidellm_rate_type: RateType = RateType.SWEEP
    guidellm_rate: Optional[List[float]] = None
    guidellm_max_seconds: int = 120
    guidellm_max_requests: Optional[MaxRequests] = None
    guidellm_output_path: str = "output.json"
    guidellm_enable_continuous_refresh: bool = False

def run(cmd: str, ignore_output=False, out_file=fp_out, err_file=fp_err) -> CmdResult:
    ran = subprocess.run(cmd, shell=True, stdout=(subprocess.DEVNULL if ignore_output else subprocess.PIPE), stderr=(subprocess.DEVNULL if ignore_output else subprocess.PIPE))
    result = CmdResult(
        ran.returncode,
        None if ignore_output else ran.stdout.decode("utf-8"),
        None if ignore_output else ran.stderr.decode("utf-8"),
    )
    if not ignore_output:
        out_file.write(str(result.stdout))
        err_file.write(str(result.stderr))
    return result

def main():

    # Ensure we have dependencies
    for name in DEPENDENCIES:
        ret = run(f"which {name}", ignore_output=True)
        if ret.rc != 0:
            print(f"Missing dependency: {name}")
            return 1

    parser = argparse.ArgumentParser()

    for field in fields(Params):
        parser.add_argument(f"--{field.name}", type=field.type, default=field.default if field.default is not MISSING else None, required=bool(field.default is MISSING))

    args = parser.parse_args()
    vargs = vars(args)

    params: Params = Params(*[vargs[field.name] for field in fields(Params)])
    if params.guidellm_output_path != "output.json":
        print("Do not change name of output file, this is not supported")
        return 1

    # Run guidellm, save results to output.json
    cli_args = []
    for field, value in asdict(params).items():
        if "guidellm" in field and value is not None:
            if type(value) is bool:
                if value:
                    cli_args.append(f"--{field.replace("guidellm_", "").replace("_", "-")}")
            else:
                cli_args.append(f"--{field.replace("guidellm_", "").replace("_", "-")}={value}")

    guidellm_cmd = "guidellm " + " ".join(cli_args)
    print(f"Running: {guidellm_cmd}")
    run(guidellm_cmd)

    # Save all settings
    with open("params.json", "w") as f:
        f.write(json.dumps(vargs, indent=4, default=lambda x: x.value))

    return 0

if __name__ == "__main__":
    sys.exit(main())
